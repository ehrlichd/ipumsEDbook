# Unit 1: The Basics {#unit1}

# Lesson 1: 

## WHAT IS DATA 


### POV:  


> In a social science class, your teacher tells you that the CDC
> reports average male height in the United States to be 69
> inches or 5ft 9in. You have been using online dating sites and
> noticed that the men you match with all report that they are
> 6ft or over. You become curious if this is a bias in reporting,
> or if the area where you live and attend college has
> significantly taller men. To test your theory, you want to
> collect data on height from individuals in your data science
> class to test if males are truly taller on campus than the
> country average. 
> 
> **Source:** https://www.cdc.gov/nchs/fastats/body-measurements.htm**


Data is defined as “facts and statistics collected together for 
reference or analysis.”^[This is from the internet and needs to 
be our words] As seen in Figure 1.1, there are two types of data:
quantitative and qualitative. **Quantitative data** are able to 
be expressed in numerical format and are countable. These data 
are either discrete or continuous where **discrete data** uses 
numeric bins. For example, we use our age as discrete 
quantitative data, we round our age to the previous year (eg., 
20, 21, 22). **Continuous data** does not use bins, but rather 
includes all of the fractions between two whole numbers. An 
example could be most physical measures like height, weight, the 
speed at which an individual runs. 



**Qualitative data** describes characteristics or categories and 
can be broken down into two categories, nominal or ordinal. 
**Nominal data** has no inherent ordering but it can be 
categorized. Examples include country or origin, gender, hair 
color, race, etc. **Ordinal data** can both be categorized and 
orders (e.g., first, second, and third place is a race).


> Going back to our hypothesis of male height on campus, heights 
> are continuous, qualitative data. It is difficult for people to
> report their specific height and you assume that most 
> individuals will report it rounded to the closest inch. This 
> makes the data you will actually use, discrete quantitative 
> data.



## COLLECTING DATA


The first step to answering a research question is to collect 
your data. Broadly, data comes in two forms, primary and 
secondary. (Fig 1.2) **Primary data** is data that is collected 
directly by the researcher. Surveys, observations, 
experimentation, questionnaires, and interviews are all examples 
of primary data. **Secondary data** is collected from published 
or unpublished literature. It is collected by different 
researchers and compiled for use by a second scientist.This type 
of data includes data found in published articles, books, 
journals, biographies, and government records like the US Census.

Once compiled, you now have a data set which is comprised of 
observations and variables. An **observation** is all of the
measures taken for one person or item. A **variable** is what is 
being measured. 

> The US CDC data is secondary, but you are collecting height 
> data yourself in class as a comparison. The survey or 
> questionnaire you use on your classmates is primary data. Each 
> individual is an observation and the variable of interest is 
> height.


## POPULATIONS AND SAMPLING
 
 
**Random Sampling:** It is a sampling method in which all the 
items have an equal chance of being selected and the individuals 
who are selected are just like the ones who are not selected

**Stratified Random Sampling:** It is a process to gather data by
separating the actual population into the distinct subset or 
strata, and then choosing simple random samples from each stratum
Your research question is about the height of all males at your 
college, but recording height data for each individual would be 
very difficult and time consuming. You instead decide to use a 
sample of males in your data science class. This is a random 
sample as each male individual has an equally likely chance of 
being samples (that is, unless a prerequisite exists).

Sampling strategy can lead to **bias**

> If you had chosen a different sample, like the men’s basketball
> team, your results would have been biased. 




# AAA "In-Class" Results {-}


### Load the Data {-}


Thanks for filling out our simple survey! Below, we'll tabulate results. Make sure to update the `data_template.xlsx` file located in: `inst/unit1_data`


```{r}

dir_path <- file.path("inst","unit1_data")
survey_path <- file.path(dir_path, "data_template.xlsx")

data <- readxl::read_excel(survey_path)
```





## Access the Data {-}

What is `data`?? Below we call the `class()` function on `data` and see that it has 3 classes: 
  `tbl_df` , `tbl` , `data.frame`
  
The first two classes, `tbl_df, tbl` indicate it is a special kind of table, in the `tibble` format. In general, you can interact with these like a `matrix` or `data.frame` but they have additional features. 


```{r}
class(data)
```



We can call `colnames()` on data, like a regular `data.frame` or `matrix`. Or we can take advantage of the `tibble` structure and use the `glimpse()` function which provides a succinct summary of your data.

```{r}

colnames(data)

tibble::glimpse(data)

```





## Summarize Data {-}

### Continuous Data {-}

For continuous data, we often want to summarize our data by describing the **mean, median, and/or range**. **Mean** and **median** describe the *central tendency* of the data, while **range** describes the full extant of the data, as seen below. 

NOTE: if `NA` are present in the data, be sure to use the `na.rm=TRUE` flag for these operations.


```{r}

mean(data$Height_inches, na.rm = T)
median(data$Height_inches, na.rm = T)
range(data$Height_inches, na.rm = T)

```




### All in summary() {-}


**Mean**, **median**, and **range** will all be reported by calling `summary()` on a `numeric vector`, such as `Height_inches`. In addition, the lower and upper quartiles will be reported, along with the number of `NA` responses.


NOTE: `summary()` does NOT require special handling for `NA` values, in fact - it expects them!

```{r}
summary(data$Height_inches)
```




### Mode Code {-}

One common measure of data reported is the mode, or most frequently occuring value. For whatever reason, this is not a default function in R, but we can easily write our own function like so:

```{r}

my_mode <- function(x){
  tt <- table(x) ## find frequencies
  tt <- tt[order(tt, decreasing = TRUE)] ## resort based on freq
  
  ## check number of modes
  max <- max(tt)
  n_max <- sum(tt==max)
  
  
  if(n_max > 1 ){
    warning("More than one mode detected")
    return(tt[tt==max])
  } else {
    ## return only the first value
    return(tt[1]) ## return whatever the highrst frequency is
  }

  
}

```

### Mode Results {-}
With this function, it's easy to find the **mode**


```{r}

my_mode(data$Height_inches)

```



## Visualizing Data {-}

The above summaries describe data with numbers, but we can also describe data visually.



### Continuous Data - Boxplots {-}


Univariate continuous data, like height, can be visualized using a box and whisker plot, which shows many of the components of summary:

  * the **median** is the black bar in the middle
  * the **quartiles** (25th and 75th percentiles) are represented by the extents of the boxes
  * The **range** is shown by the whiskers, with outliers shown indvidually, if needed.
  
  
  
```{r}
boxplot(data$Height_inches)
```


### Continuous Data - Histograms {-}

Continuous data, can also be broken into **bins** and plotted as a **histogram**. The `hist()` function will attempt to find the optimum number of bins for you, but you can specify a different number with the `breaks` argument.


```{r}
hist(data$Height_inches, main = "Histogram of Height", xlab = "Height (in)")
```




### Categorical Data {-}

Categorical data is already in discrete units. In general with categorical data, we want to count the **frequency** of unique values. There are many ways to do this, but one of the easiest is the `table()` function. Saving the results of the table to an object, `birth_freq`, allows you to save and print the results at any time.

```{r}

birth_freq <- table(data$Birth_Month)

birth_freq
```


We can also visualize our tabulated results using a **barplot** as below.


```{r}

barplot(birth_freq)

```










# Lesson 2: Intro to R, data types, data structures 

## INTRO TO R

### What is R?

R is a statistical programing language. Using R, researchers can write instructions (code) that performs just about any data manipulation, analization, or visualization.



Some highlights from the **C**omprehensive **R** **A**rchive **N**etwork (cran): 

> “R is a language and environment for statistical computing and 
> graphics…
>
> R provides a wide variety of statistical (linear and nonlinear 
> modelling, classical statistical tests, time-series analysis, 
> classification, clustering, …) and graphical techniques, and is > highly extensible. 
>
> The S language is often the vehicle of choice for research in 
> statistical methodology, and R provides an Open Source route to > participation in that activity.
>
> One of R’s strengths is the ease with which well-designed
> publication-quality plots can be produced, including 
> mathematical symbols and formulae where needed. Great care has 
> been taken over the defaults for the minor design choices in 
> graphics, but the user retains full control.
>
> R is available as Free Software under the terms of the Free 
> Software Foundation’s GNU General Public License in source code
> form. It compiles and runs on a wide variety of UNIX platforms 
> and similar systems (including FreeBSD and Linux), Windows and 
> MacOS.”


### Why use R?

### Data Structures



# Lesson 3: Distributions

## Data Distributions

### Normal Distributions

First we'll generate a normal distribution with the `rnorm()` function. This takes 3 arguments: `n, mean, sd`, which you can see filled in below. While we could print out a list of all these values, it's not easy to *understand* a list of numbers
```{r}

normal_dist <- rnorm(n = 100, ## 100 samples
                     mean = 10, ## with a mean of 10
                     sd = 1 ## and a standard deviation of 1
                     )


normal_dist
```


Another better way to look at data would be to **visualize** or **plot** it. One way to to that is with a **histogram**, which groups **continuous values** into **bins**, then plots the **frequency** for each bin. 

In R, we use the `hist()` function to plot a histogram of data. We can (try to) control the number of bins with the `breaks` argument, but note that it doesn't always match up. The `hist()` function will adjust based on the distribution of the data.

```{r norm_dist_plot}
hist(normal_dist,breaks = 5)
```

Another way to visualize this would be with a d

### What *is* normal?
#### Quantitative summaries

5num summary
* Min, 25th percentile, median, 75th percentile, Max

```{r}
tab_normal_dist <- summary(normal_dist)

```


We can print the table in R by calling its name.

```{r}
tab_normal_dist
```

Mean, standard deviation

#### Meaningful Comparisons

How to compare apples to oranges? Standardize the units / standardize the data


```{r}
data1 <- rnorm(n=1000, 
              mean = 100,
              sd = 10)

data2 <- rnorm(n=1000,
               mean = 60, 
               sd = 25)

```
Are these the same distribution?

Any issues??

```{r, rnorm_hist_comp}
layout(matrix(1:2, ncol = 2))
hist(data1)
hist(data2)
```

```{r}
total_range <- range(data1, data2)
```


Are they the same?

```{r, rnorm_hist_comp_true}
layout(matrix(1:2, ncol = 2))
hist(data1, xlim = total_range)
hist(data2, xlim = total_range)
```

Numerically / tabularly

Often times its important to tables of **summary statistics**

```{r}

norm_comp_tab <- rbind(summary(data1),
                       summary(data2))

norm_comp_tab

```


Making the table a little nicer. Also an example of **conditional programming**.


```{r}


rownames(norm_comp_tab) ## they're null


if(is.null(rownames(norm_comp_tab))){
  rownames(norm_comp_tab) <- c("data1", "data2")
}

```
When working with **Rmarkdown** we can take advantage of `knitr` and `pandoc` to nice looking tables even easier.


```{r norm_summary_tab}

knitr::kable(norm_comp_tab)
```
**How** transform the data

Simple transformation (multiply all values by 100)
  * to convert units
  * other examples?

Complex transformations
  * log-transformation (*DEE: not a fan*)
  * z-scores (*DEE: a better option*)

**Why** transform the data?
  * Real world applications?
  * Is it always appropriate to transform data?

  
### Skews

What to do if the data are **not** normal?

## Week 3: Statisitcal testing of simple data sets

### t-tests, ANOVA, chi2
## Week 4: Relationships between variables in simple data sets
### Correlation, Linear Regression
#### Simple LM
#### Complex LM
### Genearlized Linear Model
## Week 5:  

For now, I have 3 main chapters for each of the main sections: 
  * Basics of data science / R \@ref(unit1) 
  * Applications/critiques using IPUMS data \@ref(unit2)
  * Student-driven projects \@ref(unit3)

Each of these **Chapters** contains multiple sections. We'll likely want to break these sections out into their own `.Rmd` files as they get fleshed out. For now, I'll try to keep the abundance of files limited.

**NOTE:** As these actually get filled out, we will probably want to insert different `part`s to the book (EG, the content of Unit 1 is covered in `Part I`).
  * Declare parts with `# (PART) Part I {-}` immediately before the first chapter `#` it contains.
  
**Topics to include:**
  * What is data?
  * Everything can be data
  * How do we interpret data
  * Tables
  * Plots
  * Univariate distributions
  * What can they tell us
  * Multi-modality in distributions
  * Categorical vs continuous data
  * Don’t need to get ahead of this yet
  * Add in a grouping category - multi state/multi-national dataset
  * Ttest / anova

**Type of Data:**
Age distributions
Specifically generate a dataset with old/young folks over-represented to highlight a bimodal distribution

Start with single state/country
Add a second state/country to demo ttest
Add more to demo anova

Alternatively, income by education level - may be more interesting/relevant to college students (or depressing)

## Intro to R/RStudio
## Reading Data / Distributions
### What *is* a **normal distribution**
#### How normal is it?
show increasingly unclear examples of normal vs not

introduce tests of normality

#### Measuring normality - single sample

reinforce [concept of statistical] **normality**

is a value from a sample? - one way ttest
something about tails

#### comparing normality - two saples

standard / two-way t test

#### comparing more than two - ANOVA

#Glossary
Data
Quantitative
Qualitative
Discrete 
Continuous
Nominal
Ordinal

